\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{protobuf/lang}  % include language definition for protobuf
\usepackage{protobuf/style}

\newcommand{\shellcmd}[1]{\\\indent\indent\texttt{\footnotesize\$ #1}\\}
% Title Page
\title{Report on Ori Industries Assignment}
\author{Yiorgos Marinellis}


\begin{document}
\maketitle

\begin{abstract}
This text will try to present a proposed solution to the assignment
by analysing the procedure that was followed. Throughout the text
several assumptions that led to specific decisions will be described.
In the end a basic evaluation of some trade-offs will be presented.
\end{abstract}

\section{Purpose}
The scope of this exercise is to create a basic service (defined as microservice) 
which exposes a couple of methods through a gRPC interface. 

The development must be test driven and include an integration with a Continuous Integration/Continuous Delivery platform and a basic Command Line client application 
in order to access the methods.

Kubernetes deployment files in order to expose the service functionality must as well 
be created.


\section{Cloud native}
By definition from \href{https://github.com/cncf/toc/blob/master/DEFINITION.md}{Cloud Native Computing Foundation}) cloud native computing uses an open source software 
stack and is 
\begin{itemize}
    \item Containerized
    \item Dynamically orchestrated
    \item Microservice Oriented
\end{itemize}

\subsection{Containerization}
To facilitate reproducibility and resource isolation a container solution must be used.
Docker was selected for this role which nowadays is the top trend in containerization. 
The main benefit of this approach is that the application becomes independent of the environment and that the container is highly portable.
\subsection{Container Orchestration}
Containers are actively scheduled and managed to optimize resource utilization using Kubernetes. It provides load balancing (with Services) between the active application instances (replicas on a Deployment). With ConfigMap and Secrets can share configuration and authentication secrets between your containers.
Deployment to a K8S cluster can easily be done using the k8s cli inteface, \texttt{kubectl}. Deploying is fast, clean and easy. To my preference for more robust deployments I prefer to use Helm, 
currently not used for the scope of this exercise. Summarizing, Kubernetes implements all set of DevOpts for our application.


\subsection{Microservices Architecture}
Microservices Design Patterns implies  a system of multiple, relatively small applications. They work together to provide the overall functionality of your system. They 
have well defined boundaries and can autonomously developed by small teams. They provide 
simplicity over functionality and easy horizontal scaling.

Microservices remove some complexity from the services themselves but they define a distributed system with more complexity. The distributed nature of the system also makes it a lot harder to monitor and manage taking into account that for each service there might be several instances that run in parallel.




\section{Communication Protocol}
The protocol \texttt{gRPC} is an implementation for the Remote Method Invocation schema. Such schemas are used in distributed systems when a computer program wants to execute a function in a remote address space. The service exposes a skeleton for the methods 
defined to be called remotely with their parameters and return types. The client 
creates a stubs in order to access the methods on its side. The stub performs type 
checking and marshalls the called type and input parameters into a request message. 
It then sends the message over the network.
\newpage
\subsection{Data exchange}
By default gRPC uses \texttt{Protocol Buffers} as serialization mechanism. Data 
format is defined in \texttt{.proto} files. Protocol buffer data is structured as messages. The compilation of \texttt{.proto} files creates the necessary classes 
for our data, to be used from the applications we develop. Moreover, in gRPC exposed 
methods are as well defined in the \texttt{.proto} files with their parameters and 
return types.

Below is the \texttt{.proto} file I used to define message payloads and 3 methods 
that are exposed from the microservice.
\lstinputlisting[language=protobuf2,style=protobuf]{../pb/sum.proto}



\section{12factor app}

\subsection{Codebase}
The source code for the assignment is hosted on a repository Github. I usually prefer
the monorepo approach or the use of multiple repositories with submodules. On the case 
both server and client code are located in the same repo but they are treated as to 
individuals applications with separate Dockerfiles.

The CI/CD file provides the commands stages to create multiple deploys for the application.
\subsection{Dependencies}
The dependency handling in go is ,as I consider, still an open problem. I decided to 
go on with \texttt{\href{https://golang.github.io/dep/}{dep}} as it provides explicit 
dependency/version declaration and is a project with a big community in Github. Other 
solutions that I came by was \texttt{\href{https://glide.sh/}{Glide}} which was simple in 
usage but late in resolving the dependency tree and \texttt{\href{https://blog.golang.org/using-go-modules}{Go Mod}} which seem to be as well as dep a really interesting project.
\subsection{Config}
Application environment to store configuration values between deploys. For example environment variable \texttt{BIND\_PORT} was used to store the port where server listens to   and \texttt{SERVER\_ADDRESS} defines the address where the server is accessible from the client.
\subsection{Backing services}
For the specific assignment no backing services (like a database, or a message passing system) were used. In any case these applications can be deployed with standalone Kubernetes deployments and accesses as services within the cluster. Otherwise, they can
be used as SaaS cloud applications and treated as 3rd party backing services.
\subsection{Build, release, run}
For the scope of the application no release was made. According to Gitflow implementation,
releases are sepate branches from the master (production branch). Gitlab CI manages releases using tags.
\subsection{Processes}
Both applications but mainly the server (microservice) does not hold any internal state. 
It runs statelessly, calculating and return values. No write or reads to the filesystem 
happen that can change the process's state. The filesystem must only be used as a cache.
\subsection{Port binding}
The gRPC service is accessible over the network on a port defined by the deployer. On a 
Kubernetes cluster this port refers to a Pod's port. A Service has as well to be created 
either for exposing within the cluster (ClusterIP) or outside (NodePort, LoadBalancer on 
cloud providers) which will bind the Pod's port to a port specified from the deployer as well.
\subsection{Concurrency}
Golang has a pretty well defined concurrency model using lightweight goroutines. The 
gRPC implementation defines that each RPC handler attached to a registered server will be invoked in its own goroutine. The same is true for service handlers for streaming RPCs. On 
the current implementation I used \texttt{errgroup} which provides a nice error propagation method and context cancellation for groups of goroutines. This will furthermore 
enables us the functionality to run other services (like an HTTP server, eventsource) on the same app.
\subsection{Disposability}
The server handles SIGTERM by canceling the current context and waiting until all function calls from the Go method have returned before going to shutdown. 
Unexpected hardware failures are not handled.
\subsection{Dev/prod parity}
The scope of this point is to keep development and production branches on a small gap. 
This can be achieved firstly by keeping the master and development repository branches as
close as it can be and secondly by creating a common deployment mechanism for both production and development app. Assuming that we are deploying prod on a K8S cluster, we can 
\begin{itemize}
    \item deploy development on another K8S cluster keep as much as we can the same configuration
    \item deploy locally the MS app either by using docker-compose or \href{https://tilt.dev/}{Tilt}
\end{itemize}

Before committing or creating a Merge Request or deploying all kind of tests (unit, component end-to-end) should be successful on the development branch.

\subsection{Logs}
Logs are currently forwarded to stdout and can be accessed by kubectl logs. 
On this stage the log level is statically defined to INFO but it can be easily 
configured as an environment variable as well. 
Moreover, log streams can be piped to a database like Elasticsearch in order to perform 
operations on them ,like aggregations, or provide visualizations (Kibana).
\subsection{Admin processes}
The straight forward declaration of the application didn't imply any administration tasks.
Similar tasks ,like horizontal scaling, can be done on the cluster level using kubectl tool



\section{Eventsource}
We can run the http server handling an eventsource function  on a goroutine (defined on the same errgroup). We can then use streams to push events to 
the eventsource server from another goroute (eg the gRPC goroutine). A client can then subscribe to the http enpoint in order to receive the events.
\section{Monitoring}
A monitoring system for the cluster is usually provided (or can be easily installed) from the Cloud Provider. Moreover every app can expose its metrics and store them to TSDB. On top of this setup an alert system and a visualization tool are needed. I personally favor 
\texttt{Prometheus}, \texttt{Alert Manager} and \texttt{Graphana}.

\section{Functionality Access}
The easyest way to access the service from outside the cluster would be to simply expose 
the Service with a NodePort of LoadBalancer from the cloud provider. In this case the 
SSL/TLS functionality (or an authentication mechanism) is necessary.

Another solution would be to create a service which works as a client for the gRPC server 
an exposes an HTTP REST API for the request/response. I would describe it as a translation 
proxy. The HTTP service can then be accessed with an Ingress.

The MS itself can as well run a web server on a separate goroutine to expose the functionality and gRPC only for internal consumption.


\section{Conclusion}
\subsection{Notes}
Some important notes.
\begin{itemize}
 \item The directory layout used is not alligned with \texttt{go standards for package}.
 \item Their is no integration with a cloud provider
 \item The logging level of the applications is statically defined as Info
 \item No use of GoLint was used.
 \item No use of magefile
 \item Unittests for Gcd and Srqt server functions were not implemented
 \item Mock server only mocks Sum and Gcd
 \item Gitlab-Ci and Kubernetes files have not be tested on a real system
 \item Client was developed in quick 'n' dirty approach
\end{itemize}


\subsection{Improvements}
\begin{itemize}
 \item Usage of Go Mod
 \item Better organization of code in packages and modules
 \item Write more unittests, an end-to-end test or even stress tests
 \item Use Helm
 \item Add ConfigMaps to pass configuration values to Kubernetes Pods
 \item Add SSL functionality to gRPC server
 \item Try to impove builds by compiling only the files that have changed
 \item Create a more generic and robust client using cobra
 
\end{itemize}


\end{document}
